# 中国語サポート Phase 2 実装計画

## 概要

Phase 1で基本的な中国語音素化機能が実装されましたが、実用的なTTSシステムとしては以下の改善が必要です。Phase 2では、これらの制限を解消し、プロダクションレベルの中国語サポートを実現します。

## Phase 2 実装状況

### ✅ 完了したタスク

#### 1. 辞書の大規模拡張（完了）
- **実装内容**:
  - CC-CEDICTとphrase-pinyin-dataからの辞書データ統合
  - 文字数: 364 → 11,008文字（+10,644）
  - フレーズ数: 30 → 129,003フレーズ（+128,973）
  - IPAマッピング: 217 → 256（+39）
  - 単語頻度データの追加（30語）
- **成果物**:
  - `ExpandChineseDictionary.py` - 辞書拡張スクリプト
  - `character_pinyin_expanded.json` - 813KB
  - `phrase_pinyin_expanded.json` - 8.6MB
  - `ChineseExpandedDictionaryTests.cs` - テストスイート

### 🚧 実装中のタスク

#### 2. 拡張辞書のUnity統合とテスト
- **状況**: `ChineseDictionaryLoader`に拡張辞書サポートを追加済み
- **次のステップ**:
  - Unity Editorでの動作確認
  - パフォーマンステストの実行
  - メモリ使用量の最適化

### 📋 残りのタスク

#### 3. jieba風単語分割アルゴリズム（高優先度）
- **目的**: 正確な単語境界検出による音素化精度向上
- **実装内容**:
  - Directed Acyclic Graph (DAG) 構築
  - Viterbiアルゴリズムによる最適パス選択
  - 単語頻度を使用した曖昧性解消
  - 未知語の処理

#### 4. 多音字処理の拡張（高優先度）
- **現状**: 3文字のみ（不、一、了）
- **目標**: 1,000+の多音字に対応
- **実装内容**:
  - 文脈ベースの発音選択ルール
  - 品詞タグ付けによる曖昧性解消
  - 統計的モデルの導入

#### 5. 繁体字サポート（中優先度）
- **対象**: zh-TW（台湾）、zh-HK（香港）
- **実装内容**:
  - 簡体字⇔繁体字変換テーブル
  - 地域別発音バリエーション
  - 繁体字専用辞書の統合

#### 6. 辞書データ圧縮とメモリ最適化（中優先度）
- **現状**: 8.6MBのフレーズ辞書
- **目標**: 50%以上のサイズ削減
- **実装内容**:
  - トライ木（Trie）データ構造の採用
  - バイナリ形式への変換
  - 遅延読み込みの実装

#### 7. 包括的なテストカバレッジ（中優先度）
- **追加テスト**:
  - エッジケース（特殊文字、混在テキスト）
  - ストレステスト（大規模テキスト）
  - 発音精度の検証
  - 回帰テストの自動化

#### 8. 複数モデルとの互換性検証（低優先度）
- **対象モデル**:
  - zh_CN-huayan-medium（現在）
  - zh_CN-*の他のモデル
  - 音素マッピングの検証

#### 9. 統計モデルによる発音選択（低優先度）
- **実装内容**:
  - N-gramモデル
  - 隠れマルコフモデル（HMM）
  - ニューラルネットワークベースの選択

## 技術的な詳細

### 単語分割アルゴリズムの設計

```csharp
public class ChineseWordSegmenter
{
    private readonly ChinesePinyinDictionary dictionary;
    private readonly WordFrequencyModel frequencyModel;
    
    public string[] Segment(string text)
    {
        // 1. DAG構築
        var dag = BuildDAG(text);
        
        // 2. Viterbiアルゴリズムで最適パス計算
        var path = CalculateOptimalPath(dag);
        
        // 3. パスに基づいて単語分割
        return ExtractWords(text, path);
    }
}
```

### メモリ最適化の戦略

1. **データ構造の最適化**
   - HashMap → Trie木
   - 文字列の共有化
   - 重複データの削除

2. **遅延読み込み**
   - 頻度の低いフレーズは必要時のみロード
   - メモリプールの活用

3. **圧縮技術**
   - LZ4圧縮の採用
   - バイナリシリアライゼーション

## 期待される成果

### Phase 2完了時の性能指標

- **辞書カバレッジ**: 99%以上の日常会話テキスト
- **音素化精度**: 95%以上の正確性
- **処理速度**: 100文字あたり50ms以下を維持
- **メモリ使用量**: 最大15MB以内
- **対応言語**: 簡体字・繁体字両対応

### ユーザー体験の向上

1. **高精度な音声合成**: 正確な発音による自然な音声
2. **幅広いテキスト対応**: 技術文書から文学作品まで
3. **地域対応**: 中国本土、台湾、香港の発音差異に対応

## 実装スケジュール（推定）

1. **Week 1**: 拡張辞書の統合とテスト（✅完了）
2. **Week 2**: jieba風単語分割の実装
3. **Week 3**: 多音字処理の拡張
4. **Week 4**: 繁体字サポート
5. **Week 5**: 最適化とテスト

## まとめ

Phase 2の実装により、uPiperの中国語サポートは実験的レベルからプロダクションレベルへと進化します。特に辞書の大規模拡張と単語分割アルゴリズムの実装により、実用的な中国語TTSシステムが実現されます。